{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(49, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# A tensor is a multidimensional array\n",
    "# Tensorflow provides a rich library of operations\n",
    "\n",
    "print(tf.add(5,6))\n",
    "print(tf.add([1,2],[3,4]))\n",
    "print(tf.square(7))\n",
    "print(tf.reduce_sum([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n",
      "(1, 2)\n",
      "<dtype: 'int32'>\n",
      "/job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "# Each tf.Tensor has a shape and a datatype\n",
    "x = tf.matmul([[1]], [[2, 3]])\n",
    "\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)\n",
    "print(x.device)  # Gives the name of the device where the Tensor is hosted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tensors can be used be acceleratos (such as GPUs and TPUs) and are immutable\n",
    "Tensorflow operations automatically convert NumPy array to tensors and vice versa\n",
    "\n",
    "Tensors are explicitly converted to NumPy ndarrays using their .numpy() method. These conversions are typically \n",
    "cheap since the array and tf.Tensor share the underlying memory representation, if possible. However, sharing the \n",
    "underlying representation isn't always possible since the tf.Tensor may be hosted in GPU memory while NumPy arrays \n",
    "are always backed by host memory, and the conversion involves a copy from GPU to host memory.\n",
    "\n",
    "\n",
    "Refer to https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/customization/basics.ipynb for usage of devices(GPUs, CPUs, TPUs) for execution, creating datasets from your data and applying transformations to it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras API provides a way to define composition of computation layers (which are treated as objects)\n",
    "layer = tf.keras.layers.Dense(10)\n",
    "# Here the argument denotes the dimension of the output. The dimensions of the \n",
    "# can be inferred the first time the code is run or it can be specified\n",
    "# if the model is complex (or for better readability)\n",
    "\n",
    "layer = tf.keras.layers.Dense(10, input_shape=(None,5))\n",
    "\n",
    "# Here the None means that any dimension can be present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simply call a layer to use it\n",
    "layer(tf.zeros([4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_6/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       " array([[ 0.4275679 ,  0.02189386,  0.61106974, -0.04479599, -0.14924341,\n",
       "         -0.08539569, -0.17754924,  0.03136039,  0.05740136,  0.25770873],\n",
       "        [-0.60693765,  0.21552926,  0.1718939 ,  0.11161864, -0.12448686,\n",
       "          0.21869266,  0.2639873 , -0.16515723,  0.26102597,  0.5596011 ],\n",
       "        [ 0.508735  ,  0.37072748, -0.50872713,  0.55213434, -0.02300453,\n",
       "          0.17345607, -0.3412639 ,  0.55753416, -0.1414443 ,  0.25654   ],\n",
       "        [ 0.49926347,  0.2235223 ,  0.15231335, -0.30669126, -0.44596285,\n",
       "          0.15316647, -0.10717613, -0.31753978,  0.4948601 , -0.03802329],\n",
       "        [ 0.43922657,  0.3738827 ,  0.16334927,  0.3153001 , -0.39035916,\n",
       "          0.2433536 , -0.43327695,  0.49330324, -0.07920229,  0.45688254]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the trainable weights and biases in a layer\n",
    "layer.variables  # or layer.trainable_variables\n",
    "\n",
    "# Also see layer.kernel and layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import keras and check Tf version\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a model with three layers and visualize it\n",
    "inputs = keras.Input(shape=(784,))  # An input layer with 784 features (60,000 28X28 images from MNIST)\n",
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "x = dense(inputs) # This is like drawing an arrow from the input to the layer that we created\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")  # Here we compile our lauers into a model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also plot the graph for the model\n",
    "# keras.utils.plot_model(model, \"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 2s 50us/sample - loss: 0.3452 - accuracy: 0.9010 - val_loss: 0.1881 - val_accuracy: 0.9461\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.1669 - accuracy: 0.9499 - val_loss: 0.1468 - val_accuracy: 0.9586\n",
      "10000/10000 - 0s - loss: 0.1440 - accuracy: 0.9556\n",
      "Test loss: 0.1439650827549398\n",
      "Test accracy: 0.9556\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset for training\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: local_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# This saved file includes the:\n",
    "# - model architecture\n",
    "# - model weight values (that were learned during training)\n",
    "# - model training config, if any (as passed to compile)\n",
    "# - optimizer and its state, if any (to restart training where you left off)\n",
    "model.save(\"local_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
